{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82d125",
   "metadata": {
    "id": "fc82d125"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870f31ca",
   "metadata": {
    "id": "870f31ca"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcardmarketing-bbm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2950f93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "e2950f93",
    "outputId": "1a4f275b-e19a-4677-85e0-3e81a55d9b87"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d4553",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad4d4553",
    "outputId": "b471c6c8-2411-47a2-e29e-4cde8789321d"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7ccaf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebc7ccaf",
    "outputId": "4432bfb1-41ed-42e8-8a3a-f4ce7e865ed7"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cee989",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12cee989",
    "outputId": "f2c6936e-899b-4165-f3e3-26ef542ec4d3"
   },
   "outputs": [],
   "source": [
    "duplicate_rows = df[df.duplicated()]\n",
    "len(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb06b5cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb06b5cc",
    "outputId": "02b79bdd-c542-49ce-8a97-c9a12eeac20b"
   },
   "outputs": [],
   "source": [
    "df['Offer Accepted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e42fef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23e42fef",
    "outputId": "222e3c9a-89a9-44fe-9766-a8a69f6414c1"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23197a30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23197a30",
    "outputId": "5b156ff0-7eea-4f77-f578-93f7cfaa9157"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf62a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cebf62a3",
    "outputId": "81fa42e8-893b-42c0-c47c-1057d043b884"
   },
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Unique values in column '{column}':\")\n",
    "    print(unique_values)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f767a038",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f767a038",
    "outputId": "c18400f6-a296-41f1-cc57-215404d3b155"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8789c8ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8789c8ad",
    "outputId": "d40eb3bb-78b7-437f-816f-4cce7041f610"
   },
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    value_counts = df[column].value_counts()\n",
    "    print(f\"Value counts in column '{column}':\")\n",
    "    print(value_counts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030cc42f",
   "metadata": {
    "id": "030cc42f"
   },
   "outputs": [],
   "source": [
    "def categorize_size(size):\n",
    "    if size in [1, 2, 3, 4]:\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return \"Big\"\n",
    "df['Household Size'] = df['Household Size'].apply(categorize_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a62cec",
   "metadata": {
    "id": "c6a62cec"
   },
   "outputs": [],
   "source": [
    "df = df.drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81f4ce",
   "metadata": {
    "id": "7d81f4ce"
   },
   "outputs": [],
   "source": [
    "df['Offer Accepted'] = pd.Categorical(df['Offer Accepted'], categories=['No', 'Yes'])\n",
    "df['Reward'] = pd.Categorical(df['Reward'], categories=['Air Miles', 'Cash Back' ,'Points'])\n",
    "df['Mailer Type'] = pd.Categorical(df['Mailer Type'], categories=['Letter' ,'Postcard'])\n",
    "df['Overdraft Protection'] = pd.Categorical(df['Overdraft Protection'], categories=['No' ,'Yes'])\n",
    "df['Credit Rating'] = pd.Categorical(df['Credit Rating'], categories=['Low', 'Medium', 'High'],ordered=True)\n",
    "df['Household Size'] = pd.Categorical(df['Household Size'], categories=['Small', 'Big'],ordered=True)\n",
    "df['Own Your Home'] = pd.Categorical(df['Own Your Home'], categories=['No', 'Yes'])\n",
    "df['Income Level'] = pd.Categorical(df['Income Level'], categories=['Low', 'Medium', 'High'],ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8487ce2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8487ce2",
    "outputId": "67652329-c57b-429d-98bc-cdff84a62cfe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainset, testset = train_test_split(df, test_size=0.2, random_state=100)\n",
    "\n",
    "print(\"Training set shape:\", trainset.shape)\n",
    "print(\"Test set shape:\",testset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4bb144",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a4bb144",
    "outputId": "e14d1049-83ed-4508-d2c5-d8ee48bdf3ad"
   },
   "outputs": [],
   "source": [
    "trainset['Offer Accepted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390cce05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "390cce05",
    "outputId": "35baea4d-f8ec-4a65-c829-82047615dbc2"
   },
   "outputs": [],
   "source": [
    "testset['Offer Accepted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2674325",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2674325",
    "outputId": "bc84b93a-58dd-4f2e-ef06-f71b9c2b8666"
   },
   "outputs": [],
   "source": [
    "trainset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffaca1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ffaca1a",
    "outputId": "dbb98cc1-7ff6-42d2-f634-f4261f0033ad"
   },
   "outputs": [],
   "source": [
    "for column in trainset.columns:\n",
    "    value_counts = trainset[column].value_counts()\n",
    "    print(f\"Value counts in column '{column}':\")\n",
    "    print(value_counts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b9036",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "274b9036",
    "outputId": "e82c93fb-92aa-4843-b13c-6ac9d70a423d"
   },
   "outputs": [],
   "source": [
    "for column in testset.columns:\n",
    "    value_counts = testset[column].value_counts()\n",
    "    print(f\"Value counts in column '{column}':\")\n",
    "    print(value_counts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc2d6a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbc2d6a6",
    "outputId": "6ef07f56-267a-403a-ac2c-761bc772b443"
   },
   "outputs": [],
   "source": [
    "trainset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77aa962",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c77aa962",
    "outputId": "8acae6a4-b7b2-4294-fa0e-9e6a6e54e546"
   },
   "outputs": [],
   "source": [
    "testset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fae326",
   "metadata": {
    "id": "30fae326"
   },
   "outputs": [],
   "source": [
    "#Imputing missing values\n",
    "Average_Balance_mean=trainset['Average Balance'].mean()\n",
    "Q1_Balance_mean=trainset['Q1 Balance'].mean()\n",
    "Q2_Balance_mean=trainset['Q2 Balance'].mean()\n",
    "Q3_Balance_mean=trainset['Q3 Balance'].mean()\n",
    "Q4_Balance_mean=trainset['Q4 Balance'].mean()\n",
    "\n",
    "trainset['Average Balance'].fillna(Average_Balance_mean, inplace=True)\n",
    "trainset['Q1 Balance'].fillna(Q1_Balance_mean, inplace=True)\n",
    "trainset['Q2 Balance'].fillna(Q2_Balance_mean, inplace=True)\n",
    "trainset['Q3 Balance'].fillna(Q3_Balance_mean, inplace=True)\n",
    "trainset['Q4 Balance'].fillna(Q4_Balance_mean, inplace=True)\n",
    "\n",
    "testset['Average Balance'].fillna(Average_Balance_mean, inplace=True)\n",
    "testset['Q1 Balance'].fillna(Q1_Balance_mean, inplace=True)\n",
    "testset['Q2 Balance'].fillna(Q2_Balance_mean, inplace=True)\n",
    "testset['Q3 Balance'].fillna(Q3_Balance_mean, inplace=True)\n",
    "testset['Q4 Balance'].fillna(Q4_Balance_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QFKpdc13o6lg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFKpdc13o6lg",
    "outputId": "895bd6e3-8ef5-419b-a34f-53cf1c6a6ae8"
   },
   "outputs": [],
   "source": [
    "trainset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191301c",
   "metadata": {
    "id": "3191301c"
   },
   "source": [
    "## Descriptive Analysis using the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d134f48c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "id": "d134f48c",
    "outputId": "f6930c49-19cd-4881-d99d-cd73048cdcfa"
   },
   "outputs": [],
   "source": [
    "target =trainset['Offer Accepted'].value_counts()\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(target, labels = target.index, autopct = '%1.1f%%', shadow = False, explode = [0.1, 0])\n",
    "ax1.axis('equal')\n",
    "plt.show()\n",
    "print('Total number of customers in the training set:', trainset['Offer Accepted'].count())\n",
    "print(trainset['Offer Accepted'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b38726",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23b38726",
    "outputId": "5444b2b7-1890-4467-ad06-931ef403d400"
   },
   "outputs": [],
   "source": [
    "trainset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531590ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "531590ae",
    "outputId": "1647e05e-d36b-447f-d3b6-94ad72fa0190"
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='Reward', hue='Offer Accepted', data=trainset)\n",
    "\n",
    "\n",
    "total_counts = trainset['Reward'].value_counts()\n",
    "for container in ax.containers:\n",
    "    total = sum([bar.get_height() for bar in container])\n",
    "    for bar in container:\n",
    "        percentage = f'{bar.get_height() / total * 100:.2f}%'\n",
    "        ax.annotate(percentage,\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "sns.set(rc={'figure.figsize': (15, 8)})\n",
    "plt.title('Reward vs Offer Acceptance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d78e28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "20d78e28",
    "outputId": "5934a3ff-37f9-4b35-af6a-3e7f3acf6039"
   },
   "outputs": [],
   "source": [
    "categorical_col=['# Bank Accounts Open','# Credit Cards Held', '# Homes Owned','Reward', 'Mailer Type','Income Level','Overdraft Protection','Credit Rating',\n",
    "                 'Household Size', 'Own Your Home']\n",
    "for column in categorical_col:\n",
    "    ax = sns.countplot(x=column, hue='Offer Accepted', data=trainset)\n",
    "\n",
    "\n",
    "    total_counts = trainset[column].value_counts()\n",
    "    for container in ax.containers:\n",
    "        total = sum([bar.get_height() for bar in container])\n",
    "        for bar in container:\n",
    "            percentage = f'{bar.get_height() / total * 100:.2f}%'\n",
    "            ax.annotate(percentage,\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                    xytext=(0, 3), \n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "    sns.set(rc={'figure.figsize': (15, 8)})\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05028349",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "05028349",
    "outputId": "519edca4-d0a1-4f0d-c8cd-cffb4f36c640"
   },
   "outputs": [],
   "source": [
    "col = ['Reward', 'Mailer Type', 'Income Level', 'Overdraft Protection', 'Credit Rating', 'Household Size', 'Own Your Home']\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize': (15, 8)})\n",
    "\n",
    "for column in col:\n",
    "    ax = sns.countplot(x=column, hue='Offer Accepted', data=trainset)\n",
    "\n",
    "    for container in ax.containers:\n",
    "        total_heights = [bar.get_height() for bar in container]\n",
    "        yes_total = total_heights[1] if len(total_heights) > 1 else 0  \n",
    "        no_total = total_heights[0] if len(total_heights) > 0 else 0 \n",
    "\n",
    "        for i, bar in enumerate(container):\n",
    "            total = yes_total if i % 2 == 1 else no_total  \n",
    "            ax.annotate(total,\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                xytext=(0, 3),  \n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "    plt.title(f'{column} vs Offer Acceptance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02d81c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba02d81c",
    "outputId": "b983074e-a636-4f2d-db4b-ef9def8ebfe9"
   },
   "outputs": [],
   "source": [
    "trainset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f22a27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "36f22a27",
    "outputId": "d04a8a39-3478-4e06-89f0-1d2349bb0bfb"
   },
   "outputs": [],
   "source": [
    "numerical_col=['Average Balance', 'Q1 Balance',\n",
    "       'Q2 Balance', 'Q3 Balance', 'Q4 Balance']\n",
    "for column in numerical_col:\n",
    "    ax = sns.boxplot(x='Offer Accepted', y=column, data=trainset, palette=[\"red\", \"blue\"], width=0.4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e35c02",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "06e35c02",
    "outputId": "36d0d110-7ed6-4c48-8928-798311fd9878"
   },
   "outputs": [],
   "source": [
    "numerical_cols = ['# Bank Accounts Open', '# Credit Cards Held', '# Homes Owned']\n",
    "response_categories = ['No', 'Yes']\n",
    "\n",
    "sns.set(rc={'figure.figsize': (15, 8)})\n",
    "\n",
    "for column in numerical_cols:\n",
    "    ax = sns.countplot(x=column, hue='Offer Accepted', data=trainset, hue_order=response_categories)\n",
    "\n",
    "    for container in ax.containers:\n",
    "        for i, bar in enumerate(container):\n",
    "            total = bar.get_height()\n",
    "            ax.annotate(total,\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                xytext=(0, 3), \n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "    plt.title(f'{column} vs Offer Acceptance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33e490",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5d33e490",
    "outputId": "71528812-10ef-4bf5-f1db-49dddee90bec"
   },
   "outputs": [],
   "source": [
    "columns_to_plot = ['# Bank Accounts Open', '# Credit Cards Held', '# Homes Owned', 'Average Balance', 'Q1 Balance', 'Q2 Balance', 'Q3 Balance', 'Q4 Balance']\n",
    "\n",
    "sns.pairplot(trainset[columns_to_plot])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Bw7F8TfJrK-J",
   "metadata": {
    "id": "Bw7F8TfJrK-J"
   },
   "source": [
    "### MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815647b2",
   "metadata": {
    "id": "815647b2"
   },
   "outputs": [],
   "source": [
    "from prince import MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f395149",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f395149",
    "outputId": "cafdab0b-d889-45d2-c9f2-da19932d64fb"
   },
   "outputs": [],
   "source": [
    "mca_cols = trainset.select_dtypes(['category']).columns\n",
    "print(len(mca_cols), 'features used for MCA are', mca_cols.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f56ad",
   "metadata": {
    "id": "946f56ad"
   },
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, mca_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51569582",
   "metadata": {
    "id": "51569582"
   },
   "outputs": [],
   "source": [
    "df_encoded = df_encoded.drop(columns=['Customer Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835afb6f",
   "metadata": {
    "id": "835afb6f"
   },
   "outputs": [],
   "source": [
    "\n",
    "mca = MCA()\n",
    "mca_data=trainset[mca_cols]\n",
    "mca_data.head()\n",
    "\n",
    "mca1 = mca.fit(mca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459f33d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "459f33d1",
    "outputId": "e1b87b18-d67a-4abf-b06f-c69964858b47"
   },
   "outputs": [],
   "source": [
    "mca.eigenvalues_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f8b38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "df3f8b38",
    "outputId": "ab9c16cb-117c-473d-acdc-8caef9600c95"
   },
   "outputs": [],
   "source": [
    "row_coordinates=mca.row_coordinates(mca_data)\n",
    "row_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6quKwIahwD2M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "6quKwIahwD2M",
    "outputId": "896f933a-8ae4-464e-a971-4f08871dc0c7"
   },
   "outputs": [],
   "source": [
    "column_coordinates=mca.column_coordinates(mca_data)\n",
    "column_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eac326",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "96eac326",
    "outputId": "b6c9823e-dbe7-433b-eab2-ccbe698529af"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(column_coordinates[0], column_coordinates[1], marker='o', s=10, color='red')\n",
    "\n",
    "\n",
    "for label, x, y in zip(column_coordinates.index, column_coordinates[0], column_coordinates[1]):\n",
    "    plt.text(x, y, label, fontsize=5, ha='right', va='bottom')\n",
    "\n",
    "classes_to_highlight = ['Offer Accepted_No', 'Offer Accepted_Yes']\n",
    "class_coordinates_to_highlight = column_coordinates.loc[classes_to_highlight]\n",
    "plt.scatter(class_coordinates_to_highlight[0], class_coordinates_to_highlight[1], marker='o', s=10, color='blue', label='Offer Accepted')\n",
    "\n",
    "for label, x, y in zip(classes_to_highlight, class_coordinates_to_highlight[0], class_coordinates_to_highlight[1]):\n",
    "    plt.text(x, y, label, fontsize=5, ha='right', va='bottom')\n",
    "\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FqkT8iOb6pfY",
   "metadata": {
    "id": "FqkT8iOb6pfY"
   },
   "source": [
    "## PLS - DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2306ad",
   "metadata": {
    "id": "9d2306ad"
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d94f86",
   "metadata": {
    "id": "25d94f86"
   },
   "outputs": [],
   "source": [
    "X_train = trainset.drop('Offer Accepted', axis=1)\n",
    "y_train = trainset['Offer Accepted']\n",
    "X_test = testset.drop('Offer Accepted', axis=1)\n",
    "y_test = testset['Offer Accepted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ug_YOv78251I",
   "metadata": {
    "id": "Ug_YOv78251I"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "X_train_encoded = pd.get_dummies(X_train)\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "X_test_encoded = pd.get_dummies(X_test)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4XtapAESyIFg",
   "metadata": {
    "id": "4XtapAESyIFg"
   },
   "outputs": [],
   "source": [
    "n_components = 2  \n",
    "plsda = PLSRegression(n_components=n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vbeZo-tQyMQK",
   "metadata": {
    "id": "vbeZo-tQyMQK"
   },
   "outputs": [],
   "source": [
    "\n",
    "plsda.fit(X_train_encoded, y_train_encoded)\n",
    "\n",
    "X_train_plsda = plsda.transform(X_train_encoded)\n",
    "X_test_plsda = plsda.transform(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K-iAE-eGzmgh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-iAE-eGzmgh",
    "outputId": "6214cbd2-58b9-41dc-a76e-18c3daa31526"
   },
   "outputs": [],
   "source": [
    "scores = plsda.fit(X_train_encoded, y_train_encoded).x_scores_[:, :2]\n",
    "\n",
    "total_variance = np.var(X_train_encoded, axis=0).sum()\n",
    "\n",
    "scores_variance = np.var(scores, axis=0).sum()\n",
    "scores_variance\n",
    "\n",
    "variance_explained = scores_variance / total_variance\n",
    "\n",
    "print(f\"Variance explained by the first two components: {variance_explained * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v_tgXRU32RO4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "v_tgXRU32RO4",
    "outputId": "ff7931fa-f875-495a-81f6-c9ffcecccc74"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "unique_classes = np.unique(y_train_encoded)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cls in unique_classes:\n",
    "    mask = (y_train_encoded == cls)\n",
    "    plt.scatter(X_train_plsda[mask, 0], X_train_plsda[mask, 1], label=f'Class {cls}')\n",
    "\n",
    "plt.title('PLS-DA Score Plot')\n",
    "plt.xlabel('PLS-DA Component 1')\n",
    "plt.ylabel('PLS-DA Component 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pMy4TbLC8Mo-",
   "metadata": {
    "id": "pMy4TbLC8Mo-"
   },
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dZhMo5IQ7VD6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZhMo5IQ7VD6",
    "outputId": "17eb1f74-7401-4965-fca3-427a4307930e"
   },
   "outputs": [],
   "source": [
    "corr_matrix = trainset.corr(method='pearson')\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r1l1R8WT7ZIr",
   "metadata": {
    "id": "r1l1R8WT7ZIr"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pZBn14Nl7pxd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "pZBn14Nl7pxd",
    "outputId": "52167987-e190-487a-c2f4-77ff63f0d0ed"
   },
   "outputs": [],
   "source": [
    "trainset.corr(numeric_only=True, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fg8T6pXg8h9D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "id": "fg8T6pXg8h9D",
    "outputId": "270567b9-8c0b-4a31-9aff-68104cd23835"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "sns.heatmap(trainset.corr(numeric_only=True), annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9e6fab",
   "metadata": {},
   "source": [
    "# Advanced Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae985ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset['Offer Accepted'] = trainset['Offer Accepted'].replace({'No': 0, 'Yes': 1})\n",
    "testset['Offer Accepted'] = testset['Offer Accepted'].replace({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de9e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b772f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = trainset.drop('Offer Accepted', axis=1)\n",
    "y_train = trainset['Offer Accepted']\n",
    "X_test = testset.drop('Offer Accepted', axis=1)\n",
    "y_test = testset['Offer Accepted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_mapping = {\n",
    "    'Credit Rating': ['Low', 'Medium', 'High'],\n",
    "    'Household Size': ['Small', 'Big'],\n",
    "    'Income Level': ['Low', 'Medium', 'High']\n",
    "}\n",
    "\n",
    "for column, categories in ordinal_mapping.items():\n",
    "    X_train[column] = pd.Categorical(X_train[column], categories=categories, ordered=True).codes\n",
    "    X_test[column] = pd.Categorical(X_test[column], categories=categories, ordered=True).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a18e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_columns = ['Reward', 'Mailer Type', 'Income Level', 'Overdraft Protection', 'Credit Rating', 'Household Size', 'Own Your Home']\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns=nominal_columns, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=nominal_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de49d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2af9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['Customer Number'])\n",
    "X_test = X_test.drop(columns=['Customer Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.to_csv('trainset.csv', index=False)\n",
    "testset.to_csv('testset.csv', index=False)\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "X_test.to_csv('X_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d9609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c8e31",
   "metadata": {},
   "source": [
    "### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ccdeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_columns = ['# Bank Accounts Open', '# Credit Cards Held', '# Homes Owned',\n",
    "                     'Average Balance', 'Q1 Balance', 'Q2 Balance', 'Q3 Balance', 'Q4 Balance']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled[numerical_columns] = scaler.fit_transform(X_train_scaled[numerical_columns])\n",
    "\n",
    "X_test_scaled = X_test.copy()  \n",
    "X_test_scaled[numerical_columns] = scaler.transform(X_test_scaled[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc736db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "import joblib\n",
    "\n",
    "random_state = 42\n",
    "classifiers = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000)),\n",
    "    ('Logistic Ridge', LogisticRegression(penalty='l2', max_iter=1000)),\n",
    "    ('Logistic Lasso', LogisticRegression(penalty='l1',solver='liblinear')),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('Gaussian Naive Bayes', GaussianNB()),\n",
    "    ('SVM Linear', SVC(kernel='linear', probability=True, random_state=42)),\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('XGBoost', XGBClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "\n",
    "results = {}\n",
    "classification_reports = {}\n",
    "trained_models = {}\n",
    "\n",
    "for name, clf in classifiers:\n",
    "\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    trained_models[name] = clf \n",
    "\n",
    "    y_pred = clf.predict(X_train_scaled)\n",
    "    classification_report_text = classification_report(y_train, y_pred)\n",
    "    accuracy = accuracy_score(y_train, y_pred)\n",
    "    f1 = f1_score(y_train, y_pred)\n",
    "    precision = precision_score(y_train, y_pred)\n",
    "    recall = recall_score(y_train, y_pred)\n",
    "    \n",
    "    classification_reports[name] = classification_report_text\n",
    "    results[name] = {'Accuracy': accuracy, 'F1-Score': f1, 'Precision': precision, 'Recall': recall}\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "for name, report in classification_reports.items():\n",
    "    print(f\"Classification Report for {name}:\\n{report}\")\n",
    "    \n",
    "for name, model in trained_models.items():\n",
    "    filename = f\"{name}_model.joblib\"\n",
    "    joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991df303",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "classification_reports = {}\n",
    "\n",
    "for name, clf in trained_models.items():\n",
    "    y_pred = clf.predict(X_test_scaled) \n",
    "    classification_report_text = classification_report(y_test, y_pred) \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    classification_reports[name] = classification_report_text\n",
    "    results[name] = {'Accuracy': accuracy, 'F1-Score': f1, 'Precision': precision, 'Recall': recall}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "for name, report in classification_reports.items():\n",
    "    print(f\"Classification Report for {name}:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f23076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "classes = ['Not accepted', 'Accepted']\n",
    "\n",
    "confusion_matrices = {}\n",
    "\n",
    "for name, clf in trained_models.items():\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices[name] = cm\n",
    "\n",
    "for name, cm in confusion_matrices.items():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9bd0f",
   "metadata": {},
   "source": [
    "## Applying  balancing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dffaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "resampling_methods = {\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    'RandomUnderSampler': RandomUnderSampler(random_state=42)\n",
    "}\n",
    "\n",
    "classifiers = [\n",
    "    ('Logistic Regression', LogisticRegression()),\n",
    "    ('Logistic Ridge', LogisticRegression(penalty='l2', max_iter=1000)),\n",
    "    ('Logistic Lasso', LogisticRegression(penalty='l1', solver='liblinear')),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('Gaussian Naive Bayes', GaussianNB()),\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('XGBoost', XGBClassifier(random_state=42)),\n",
    "    ('SVM Linear', SVC(kernel='linear', probability=True, random_state=42))\n",
    "]\n",
    "\n",
    "results = {}\n",
    "modified_trained_models = {}\n",
    "classification_reports = {}\n",
    "\n",
    "for resampling_name, resampling_method in resampling_methods.items():\n",
    "    print(f\"Applying {resampling_name}...\")\n",
    "    \n",
    "    X_resampled, y_resampled = resampling_method.fit_resample(X_train_scaled, y_train)\n",
    "    \n",
    "    for name, clf in classifiers:\n",
    "        clf.fit(X_resampled, y_resampled)\n",
    "        modified_trained_models[(resampling_name, name)] = clf \n",
    "\n",
    "        y_probs = clf.predict_proba(X_train_scaled)[:, 1]\n",
    "\n",
    "        precision, recall, thresholds = precision_recall_curve(y_train, y_probs)\n",
    "\n",
    "        pr_auc = auc(recall, precision)\n",
    "        \n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "        optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "        print(f\"Optimal Threshold for {name}: {optimal_threshold}\")\n",
    "        \n",
    "        y_pred_optimal = (y_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "        report = classification_report(y_train, y_pred_optimal)\n",
    "        classification_reports[(resampling_name, name)] = report\n",
    "\n",
    "for (resampling_name, model_name), model in modified_trained_models.items():\n",
    "    filename = f\"{resampling_name.lower()}_{model_name}_model.joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "for (resampling_name, model_name), report in classification_reports.items():\n",
    "    print(f\"\\nClassification Report for {resampling_name} - {model_name}:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2420c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "test_classification_reports = {}\n",
    "\n",
    "for (resampling_name, model_name), clf in modified_trained_models.items():\n",
    "    \n",
    "    \n",
    "    model_filename = f\"{resampling_name.lower()}_{model_name}_model.joblib\"\n",
    "    trained_model = joblib.load(model_filename)\n",
    "\n",
    "    \n",
    "    y_probs_test = trained_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_pred_optimal_test = (y_probs_test >= optimal_threshold).astype(int)\n",
    "\n",
    "    \n",
    "    test_report = classification_report(y_test, y_pred_optimal_test)\n",
    "    test_classification_reports[(resampling_name, model_name)] = test_report\n",
    "\n",
    "\n",
    "for (resampling_name, model_name), test_report in test_classification_reports.items():\n",
    "    print(f\"\\nClassification Report for {resampling_name} - {model_name} (on test set):\\n{test_report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada60d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_smote = joblib.load('smote_Random Forest_model.joblib')\n",
    "rf_model_us = joblib.load('randomundersampler_Random Forest_model.joblib')\n",
    "feature_names = X_train.columns\n",
    "\n",
    "feature_importances_smote = rf_model_smote.feature_importances_\n",
    "importance_df_smote = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances_smote})\n",
    "importance_df_smote = importance_df_smote.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df_smote['Feature'], importance_df_smote['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Variable Importance - SMOTE Random Forest')\n",
    "plt.show()\n",
    "\n",
    "feature_importances_us = rf_model_us.feature_importances_\n",
    "importance_df_us = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances_us})\n",
    "importance_df_us = importance_df_us.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df_us['Feature'], importance_df_us['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Variable Importance - Under Sampled Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db6975",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled_smote, y_resampled_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "rf_classifier_smote = RandomForestClassifier(random_state=42)\n",
    "grid_search_smote = GridSearchCV(rf_classifier_smote, param_grid, cv=StratifiedKFold(n_splits=5), scoring='f1', n_jobs=-1)\n",
    "grid_search_smote.fit(X_resampled_smote, y_resampled_smote)\n",
    "\n",
    "best_model_smote = grid_search_smote.best_estimator_\n",
    "\n",
    "print(\"Best parameters for SMOTE model:\", grid_search_smote.best_params_)\n",
    "\n",
    "y_pred_smote = best_model_smote.predict(X_test_scaled)\n",
    "\n",
    "report_smote = classification_report(y_test, y_pred_smote)\n",
    "print(\"Classification Report for the tuned SMOTE model:\")\n",
    "print(report_smote)\n",
    "\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled_undersampler, y_resampled_undersampler = undersampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "rf_classifier_undersampler = RandomForestClassifier(random_state=42)\n",
    "grid_search_undersampler = GridSearchCV(rf_classifier_undersampler, param_grid, cv=StratifiedKFold(n_splits=5), scoring='f1', n_jobs=-1)\n",
    "grid_search_undersampler.fit(X_resampled_undersampler, y_resampled_undersampler)\n",
    "\n",
    "best_model_undersampler = grid_search_undersampler.best_estimator_\n",
    "\n",
    "\n",
    "print(\"Best parameters for Random Undersampler model:\", grid_search_undersampler.best_params_)\n",
    "\n",
    "y_pred_undersampler = best_model_undersampler.predict(X_test_scaled)\n",
    "\n",
    "report_undersampler = classification_report(y_test, y_pred_undersampler)\n",
    "print(\"Classification Report for the tuned Random Undersampler model:\")\n",
    "print(report_undersampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc0af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_smote = best_model_smote.predict(X_train_scaled)\n",
    "\n",
    "report_smote = classification_report(y_train, y_pred_smote)\n",
    "print(\"Classification Report for the tuned SMOTE model:\")\n",
    "print(report_smote)\n",
    "\n",
    "y_pred_undersampler = best_model_undersampler.predict(X_train_scaled)\n",
    "report_undersampler = classification_report(y_train, y_pred_undersampler)\n",
    "print(\"Classification Report for the tuned Random Undersampler model:\")\n",
    "print(report_undersampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa50b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "}\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled_smote, y_resampled_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "xgb_classifier_smote = XGBClassifier(random_state=42)\n",
    "grid_search_smote_xgb = GridSearchCV(xgb_classifier_smote, param_grid_xgb, cv=StratifiedKFold(n_splits=5), scoring='f1', n_jobs=-1)\n",
    "grid_search_smote_xgb.fit(X_resampled_smote, y_resampled_smote)\n",
    "\n",
    "best_model_smote_xgb = grid_search_smote_xgb.best_estimator_\n",
    "\n",
    "print(\"Best parameters for SMOTE XGBoost model:\", grid_search_smote_xgb.best_params_)\n",
    "\n",
    "y_pred_smote_xgb = best_model_smote_xgb.predict(X_test_scaled)\n",
    "\n",
    "report_smote_xgb = classification_report(y_test, y_pred_smote_xgb)\n",
    "print(\"Classification Report for the tuned SMOTE XGBoost model:\")\n",
    "print(report_smote_xgb)\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled_undersampler, y_resampled_undersampler = undersampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "xgb_classifier_undersampler = XGBClassifier(random_state=42)\n",
    "grid_search_undersampler_xgb = GridSearchCV(xgb_classifier_undersampler, param_grid_xgb, cv=StratifiedKFold(n_splits=5), scoring='f1', n_jobs=-1)\n",
    "grid_search_undersampler_xgb.fit(X_resampled_undersampler, y_resampled_undersampler)\n",
    "\n",
    "best_model_undersampler_xgb = grid_search_undersampler_xgb.best_estimator_\n",
    "\n",
    "print(\"Best parameters for Random Undersampler XGBoost model:\", grid_search_undersampler_xgb.best_params_)\n",
    "\n",
    "y_pred_undersampler_xgb = best_model_undersampler_xgb.predict(X_test_scaled)\n",
    "\n",
    "report_undersampler_xgb = classification_report(y_test, y_pred_undersampler_xgb)\n",
    "print(\"Classification Report for the tuned Random Undersampler XGBoost model:\")\n",
    "print(report_undersampler_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_smote = best_model_smote_xgb.predict(X_train_scaled)\n",
    "\n",
    "report_smote = classification_report(y_train, y_pred_smote)\n",
    "print(\"Classification Report for the tuned SMOTE model:\")\n",
    "print(report_smote)\n",
    "\n",
    "\n",
    "y_pred_undersampler = best_model_undersampler_xgb.predict(X_train_scaled)\n",
    "\n",
    "report_undersampler = classification_report(y_train, y_pred_undersampler)\n",
    "print(\"Classification Report for the tuned Random Undersampler model:\")\n",
    "print(report_undersampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b4680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def generate_color_gradient(importances):\n",
    "    norm_importances = (importances - min(importances)) / (max(importances) - min(importances))\n",
    "    \n",
    "    # Define a custom colormap starting from light blue and degrading towards dark blue\n",
    "    cmap = LinearSegmentedColormap.from_list('custom_gradient', ['#99CCFF', '#66B2FF', '#0089FF', '#0071D7', '#0058A9', '#00407A', '#00274C'])\n",
    "\n",
    "    colors = cmap(norm_importances)\n",
    "    return colors\n",
    "\n",
    "feature_importances_smote = best_model_smote.feature_importances_\n",
    "sorted_idx_smote = feature_importances_smote.argsort()\n",
    "\n",
    "colors_smote = generate_color_gradient(feature_importances_smote)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(X_train_scaled.shape[1]), feature_importances_smote[sorted_idx_smote], color=colors_smote[sorted_idx_smote])\n",
    "plt.yticks(range(X_train_scaled.shape[1]), X_train.columns[sorted_idx_smote])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Variable Importance Plot for SMOTE-Random Forest model')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "feature_importances_undersampler = best_model_undersampler.feature_importances_\n",
    "sorted_idx_undersampler = feature_importances_undersampler.argsort()\n",
    "\n",
    "colors_undersampler = generate_color_gradient(feature_importances_undersampler)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(X_train_scaled.shape[1]), feature_importances_undersampler[sorted_idx_undersampler], color=colors_undersampler[sorted_idx_undersampler])\n",
    "plt.yticks(range(X_train_scaled.shape[1]), X_train.columns[sorted_idx_undersampler])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Variable Importance Plot for Random Undersampler-Random Forest model')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "feature_importances_smote = best_model_smote_xgb.feature_importances_\n",
    "sorted_idx_smote = feature_importances_smote.argsort()\n",
    "\n",
    "colors_smote = generate_color_gradient(feature_importances_smote)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(X_train_scaled.shape[1]), feature_importances_smote[sorted_idx_smote], color=colors_smote[sorted_idx_smote])\n",
    "plt.yticks(range(X_train_scaled.shape[1]), X_train.columns[sorted_idx_smote])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Variable Importance Plot for SMOTE-XGBoost model')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "feature_importances_undersampler = best_model_undersampler_xgb.feature_importances_\n",
    "sorted_idx_undersampler = feature_importances_undersampler.argsort()\n",
    "\n",
    "colors_undersampler = generate_color_gradient(feature_importances_undersampler)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(X_train_scaled.shape[1]), feature_importances_undersampler[sorted_idx_undersampler], color=colors_undersampler[sorted_idx_undersampler])\n",
    "plt.yticks(range(X_train_scaled.shape[1]), X_train.columns[sorted_idx_undersampler])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Variable Importance Plot for Random Undersampler-XGBoost model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef3d9c",
   "metadata": {},
   "source": [
    "## Voting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cf4e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "xgb_smote_classifier = best_model_smote_xgb\n",
    "rf_smote_classifier = best_model_smote\n",
    "\n",
    "ensemble_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb_smote', xgb_smote_classifier),\n",
    "        ('rf_smote', rf_smote_classifier)\n",
    "    ],\n",
    "    voting='soft' \n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled_smote, y_resampled_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "ensemble_classifier.fit(X_resampled_smote, y_resampled_smote)\n",
    "\n",
    "\n",
    "y_pred_train = ensemble_classifier.predict(X_train_scaled)\n",
    "\n",
    "\n",
    "report_ensemble = classification_report(y_train, y_pred_train)\n",
    "print(\"Classification Report for the Ensemble Classifier:\")\n",
    "print(report_ensemble)\n",
    "\n",
    "\n",
    "y_pred_test = ensemble_classifier.predict(X_test_scaled)\n",
    "\n",
    "report_ensemble = classification_report(y_test, y_pred_test)\n",
    "print(\"Classification Report for the Ensemble Classifier:\")\n",
    "print(report_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03f5c72",
   "metadata": {},
   "source": [
    "# Reduced Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd26f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'Q1 Balance', 'Q2 Balance', 'Q3 Balance','Q4 Balance', \n",
    "    'Average Balance', 'Credit Rating_2', 'Mailer Type_Postcard',\n",
    "    'Reward_Cash Back','Credit Rating_1',  '# Credit Cards Held']\n",
    "\n",
    "X_train_scaled_selected = X_train_scaled[selected_features]\n",
    "X_test_scaled_selected = X_test_scaled[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ab37a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "import joblib\n",
    "\n",
    "random_state = 42\n",
    "classifiers = [\n",
    "    ('reduced_Logistic Regression', LogisticRegression(max_iter=1000)),\n",
    "    ('reduced_Logistic Ridge', LogisticRegression(penalty='l2', max_iter=1000)),\n",
    "    ('reduced_Logistic Lasso', LogisticRegression(penalty='l1',solver='liblinear')),\n",
    "    ('reduced_KNN', KNeighborsClassifier()),\n",
    "    ('reduced_Gaussian Naive Bayes', GaussianNB()),\n",
    "    ('reduced_SVM Linear', SVC(kernel='linear', probability=True, random_state=42)),\n",
    "    ('reduced_Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('reduced_XGBoost', XGBClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "\n",
    "results = {}\n",
    "classification_reports = {}\n",
    "reduced_trained_models = {}\n",
    "\n",
    "for name, clf in classifiers:\n",
    "\n",
    "    clf.fit(X_train_scaled_selected, y_train)\n",
    "\n",
    "    reduced_trained_models[name] = clf \n",
    "\n",
    "    y_pred = clf.predict(X_train_scaled_selected)\n",
    "    classification_report_text = classification_report(y_train, y_pred)\n",
    "    accuracy = accuracy_score(y_train, y_pred)\n",
    "    f1 = f1_score(y_train, y_pred)\n",
    "    precision = precision_score(y_train, y_pred)\n",
    "    recall = recall_score(y_train, y_pred)\n",
    "    \n",
    "    classification_reports[name] = classification_report_text\n",
    "    results[name] = {'Accuracy': accuracy, 'F1-Score': f1, 'Precision': precision, 'Recall': recall}\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "for name, report in classification_reports.items():\n",
    "    print(f\"Classification Report for {name}:\\n{report}\")\n",
    "    \n",
    "for name, model in reduced_trained_models.items():\n",
    "    filename = f\"{name}_model.joblib\"\n",
    "    joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "classification_reports = {}\n",
    "\n",
    "for name, clf in reduced_trained_models.items():\n",
    "    y_pred = clf.predict(X_test_scaled_selected) \n",
    "    classification_report_text = classification_report(y_test, y_pred) \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    classification_reports[name] = classification_report_text\n",
    "    results[name] = {'Accuracy': accuracy, 'F1-Score': f1, 'Precision': precision, 'Recall': recall}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "for name, report in classification_reports.items():\n",
    "    print(f\"Classification Report for {name}:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c172486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "resampling_methods = {\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    'RandomUnderSampler': RandomUnderSampler(random_state=42)\n",
    "}\n",
    "\n",
    "classifiers = [\n",
    "    ('reduced_Logistic Regression', LogisticRegression(max_iter=1000)),\n",
    "    ('reduced_Logistic Ridge', LogisticRegression(penalty='l2', max_iter=1000)),\n",
    "    ('reduced_Logistic Lasso', LogisticRegression(penalty='l1',solver='liblinear')),\n",
    "    ('reduced_KNN', KNeighborsClassifier()),\n",
    "    ('reduced_Gaussian Naive Bayes', GaussianNB()),\n",
    "    ('reduced_SVM Linear', SVC(kernel='linear', probability=True, random_state=42)),\n",
    "    ('reduced_Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('reduced_XGBoost', XGBClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "results = {}\n",
    "modified_reduced_trained_models = {}\n",
    "classification_reports = {}\n",
    "\n",
    "for resampling_name, resampling_method in resampling_methods.items():\n",
    "    print(f\"Applying {resampling_name}...\")\n",
    "    \n",
    "    X_resampled, y_resampled = resampling_method.fit_resample(X_train_scaled_selected, y_train)\n",
    "    \n",
    "    for name, clf in classifiers:\n",
    "        clf.fit(X_resampled, y_resampled)\n",
    "        modified_reduced_trained_models[(resampling_name, name)] = clf \n",
    "\n",
    "     \n",
    "        y_probs = clf.predict_proba(X_train_scaled_selected)[:, 1]\n",
    "\n",
    "\n",
    "        precision, recall, thresholds = precision_recall_curve(y_train, y_probs)\n",
    "\n",
    "\n",
    "        pr_auc = auc(recall, precision)\n",
    "        \n",
    "\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "        optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "        print(f\"Optimal Threshold for {name}: {optimal_threshold}\")\n",
    "        \n",
    "\n",
    "        y_pred_optimal = (y_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "\n",
    "        report = classification_report(y_train, y_pred_optimal)\n",
    "        classification_reports[(resampling_name, name)] = report\n",
    "\n",
    "for (resampling_name, model_name), model in modified_reduced_trained_models.items():\n",
    "    filename = f\"{resampling_name.lower()}_{model_name}_model.joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "\n",
    "for (resampling_name, model_name), report in classification_reports.items():\n",
    "    print(f\"\\nClassification Report for {resampling_name} - {model_name}:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c8f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "test_classification_reports = {}\n",
    "\n",
    "for (resampling_name, model_name), clf in modified_reduced_trained_models.items():\n",
    "    \n",
    "    \n",
    "    model_filename = f\"{resampling_name.lower()}_{model_name}_model.joblib\"\n",
    "    trained_model = joblib.load(model_filename)\n",
    "\n",
    "    y_probs_test = trained_model.predict_proba(X_test_scaled_selected)[:, 1]\n",
    "    y_pred_optimal_test = (y_probs_test >= optimal_threshold).astype(int)\n",
    "\n",
    "    test_report = classification_report(y_test, y_pred_optimal_test)\n",
    "    test_classification_reports[(resampling_name, model_name)] = test_report\n",
    "\n",
    "\n",
    "for (resampling_name, model_name), test_report in test_classification_reports.items():\n",
    "    print(f\"\\nClassification Report for {resampling_name} - {model_name} (on test set):\\n{test_report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled_smote, y_resampled_smote = smote.fit_resample(X_train_scaled_selected, y_train)\n",
    "\n",
    "rf_classifier_smote = RandomForestClassifier(random_state=42)\n",
    "grid_search_smote = GridSearchCV(rf_classifier_smote, param_grid, cv=StratifiedKFold(n_splits=5), scoring='f1', n_jobs=-1)\n",
    "grid_search_smote.fit(X_resampled_smote, y_resampled_smote)\n",
    "\n",
    "best_reduced_model_smote = grid_search_smote.best_estimator_\n",
    "\n",
    "print(\"Best parameters for SMOTE model:\", grid_search_smote.best_params_)\n",
    "\n",
    "y_pred_smote = best_reduced_model_smote.predict(X_test_scaled_selected)\n",
    "\n",
    "report_smote = classification_report(y_test, y_pred_smote)\n",
    "print(\"Classification Report for the tuned SMOTE model:\")\n",
    "print(report_smote)\n",
    "\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "}\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled_smote, y_resampled_smote = smote.fit_resample(X_train_scaled_selected, y_train)\n",
    "\n",
    "xgb_classifier_smote = XGBClassifier(random_state=42)\n",
    "grid_search_smote_xgb = GridSearchCV(xgb_classifier_smote, param_grid_xgb, cv=StratifiedKFold(n_splits=5), scoring='f1', n_jobs=-1)\n",
    "grid_search_smote_xgb.fit(X_resampled_smote, y_resampled_smote)\n",
    "\n",
    "best_reduced_model_smote_xgb = grid_search_smote_xgb.best_estimator_\n",
    "\n",
    "print(\"Best parameters for SMOTE XGBoost model:\", grid_search_smote_xgb.best_params_)\n",
    "\n",
    "y_pred_smote_xgb = best_reduced_model_smote_xgb.predict(X_test_scaled_selected)\n",
    "\n",
    "report_smote_xgb = classification_report(y_test, y_pred_smote_xgb)\n",
    "print(\"Classification Report for the tuned SMOTE XGBoost model:\")\n",
    "print(report_smote_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdebd715",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_smote = best_reduced_model_smote.predict(X_train_scaled_selected)\n",
    "\n",
    "report_smote = classification_report(y_train, y_pred_smote)\n",
    "print(\"Classification Report for the tuned SMOTE model:\")\n",
    "print(report_smote)\n",
    "\n",
    "\n",
    "y_pred_smote_xgb = best_reduced_model_smote_xgb.predict(X_train_scaled_selected)\n",
    "\n",
    "report_smote_xgb = classification_report(y_train, y_pred_smote_xgb)\n",
    "print(\"Classification Report for the tuned SMOTE XGBoost model:\")\n",
    "print(report_smote_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d759533",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d057a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Load the pre-trained models\n",
    "best_reduced_model_knn = joblib.load(\"smote_reduced_KNN_model.joblib\")\n",
    "xgb_reduced_smote = best_reduced_model_smote_xgb\n",
    "rf_reduced_smote= best_reduced_model_smote\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb_smote', xgb_reduced_smote),\n",
    "        ('rf_smote', rf_reduced_smote),\n",
    "        ('KNN', best_reduced_model_knn)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "voting_classifier.fit(X_resampled_smote, y_resampled_smote)\n",
    "\n",
    "y_pred_ensemble = voting_classifier.predict(X_train_scaled_selected)\n",
    "\n",
    "report_ensemble = classification_report(y_train, y_pred_ensemble)\n",
    "print(\"Classification Report for the Ensemble Model:\")\n",
    "print(report_ensemble)\n",
    "y_pred_ensemble = voting_classifier.predict(X_test_scaled_selected)\n",
    "\n",
    "report_ensemble = classification_report(y_test, y_pred_ensemble)\n",
    "print(\"Classification Report for the Ensemble Model:\")\n",
    "print(report_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bc25b1",
   "metadata": {},
   "source": [
    "### Partial Dependence plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1fb8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "features_to_plot = [    'Q1 Balance', 'Q2 Balance', 'Q3 Balance','Q4 Balance', \n",
    "    'Average Balance', 'Credit Rating_2', 'Mailer Type_Postcard',\n",
    "    'Reward_Cash Back','Credit Rating_1',  '# Credit Cards Held']\n",
    "\n",
    "disp1 = PartialDependenceDisplay.from_estimator(best_reduced_model_smote, X_train_scaled_selected,\n",
    "                                                ['Q1 Balance'])\n",
    "plt.show()\n",
    "disp1 = PartialDependenceDisplay.from_estimator(best_reduced_model_smote, X_train_scaled_selected,\n",
    "                                                ['Q2 Balance'])\n",
    "plt.show()\n",
    "disp1 = PartialDependenceDisplay.from_estimator(best_reduced_model_smote, X_train_scaled_selected,\n",
    "                                                ['Q3 Balance'])\n",
    "plt.show()\n",
    "disp1 = PartialDependenceDisplay.from_estimator(best_reduced_model_smote, X_train_scaled_selected,\n",
    "                                                ['Q4 Balance'])\n",
    "plt.show()\n",
    "disp1 = PartialDependenceDisplay.from_estimator(best_reduced_model_smote, X_train_scaled_selected,\n",
    "                                                ['Average Balance'])\n",
    "plt.show()\n",
    "disp1 = PartialDependenceDisplay.from_estimator(best_reduced_model_smote, X_train_scaled_selected,\n",
    "                                                ['Credit Rating_2'])\n",
    "plt.show()\n",
    "disp1 = PartialDependenceDisplay.from_estimator(best_reduced_model_smote, X_train_scaled_selected,\n",
    "                                                ['Mailer Type_Postcard'])\n",
    "plt.show()\n",
    "disp1 = PartialDependenceDisplay.from_estimator(best_reduced_model_smote, X_train_scaled_selected,\n",
    "                                                ['Reward_Cash Back'])\n",
    "plt.show()\n",
    "disp1 = PartialDependenceDisplay.from_estimator(best_reduced_model_smote, X_train_scaled_selected,\n",
    "                                                ['# Credit Cards Held'])\n",
    "plt.show()\n",
    "disp1 = PartialDependenceDisplay.from_estimator(best_reduced_model_smote, X_train_scaled_selected,\n",
    "                                                ['Credit Rating_1'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
